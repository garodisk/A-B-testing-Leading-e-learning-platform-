# A-B-testing-Leading-e-learning-platform-
Analyzing the different metrics and conducting a A/B test to analyze whether a new feature should be implemented for a leading -Learning platform

# **1. Introduction**

This notebook contains a detailed report about an experiment conducted by a **leading e-learning platform** to analyze whether to include a new feature on their course overview page.

The experiment that I am talking about is **A/B testing** where some users are allotted to a control group while some are put in an experiment group and a variety of metrics and statistics designed before an experiment is analyzed to gauge whether the feature should be implemented as per the needs of the company.

**More specifically**, an experimental step would be added after the “Start Free Trial” button on the course page. Based on this experiment, after clicking on the “Start Free Trial” button, a message would be shown asking users the weekly time that they want to invest on the course. If the input hours is below 5 hours per week, “a message would appear indicating that the course usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free.”

The **goal of the experiment** is reducing the number of students who would quit the course during the starting 14days period, while leaving the number of studnets who pass this 14days period intact. I would like to call the first group of students, “frustrated”, and the second group, “resolute” students.

I have provided the following image based on the provided data on Final Project Instructions and Baseline Values.

**Contents:**

**1) Introduction**

**2) Metric Choice**

**3) Measure of variability**

**4) Sizing**

**5) Sanity Check**

**6) Effect Size Tests**

